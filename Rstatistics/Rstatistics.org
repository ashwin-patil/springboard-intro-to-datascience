# -*- eval: (save-excursion (org-babel-goto-named-src-block "workshopPreamble") (org-babel-execute-src-block)) -*-
#+TITLE:     Regression Models in R
#+AUTHOR:    
#+EMAIL:     dataclass@help.hmdc.harvard.edu
#+DATE:      

# NOTE: refer to the README file if you are unfamiliar with emacs or orgmode.

# Customize the PROPERTY and EXCLUDE_TAGS below depending on the type
# of export (see the README file for details). After setting the exports 
# property and/or the EXCLUDE_TAGS, place the curser on the poperty line 
# and press C-c C-c

#+PROPERTY: header-args :exports code
#+PROPERTY: header-args:R  :session *R*

#+EXCLUDE_TAGS: noexport mitsetup
#+OPTIONS: toc:nil





#+SETUPFILE: ../workshopPreamble.org

#+name: workshopPreamble
#+begin_src emacs-lisp :exports none :results silent :tangle no
  (load-file "../setupEnvironment.el")
#+end_src

#+name: setupR
#+begin_src R :exports none :tangle no :results silent
  rm(list=ls())
  .First <- function() {
    options(width=70)
    options(useFancyQuotes=FALSE)
    options(show.signif.stars=FALSE)
    options(scipen = 10)
    options(digits = 3)
  }
#+end_src


* Introduction

** Workshop description

- This is an intermediate/advanced R course
- Appropriate for those with basic knowledge of R
- This is not a statistics course! 
- Learning objectives:
  - Learn the R formula interface
  - Specify factor contrasts to test specific hypotheses
  - Perform model comparisons
  - Run and interpret variety of regression models in R

** Materials and Setup						   :labsetup:

Lab computer users: Log in using the user name and password on the board to your left.

Laptop users:  
- you should have R installed--if not, open a web browser and go to [[http://cran.r-project.org]] and download and install it
- also helpful to install RStudo (download from [[http://rstudio.com]])

Everyone:
- Download materials from [[http://tutorials.iq.harvard.edu/R/Rstatistics.zip]]
- Extract materials from RStatistics.zip (on lab machines /right-click -> WinZip -> Extract to here/) and move to your desktop.

** Launch RStudio						   :labsetup:

- Open the RStudio program from the Windows start menu
- Open up today's R script
  - In RStudio, Go to *File => Open Script*
  - Locate and open the =Rstatistics.R= script in the Rstatistics folder on your desktop
- Go to *Tools => Set working directory => To source file location* (more on the working directory later)
- I encourage you to add your own notes to this file!
  

** Copy the workshop materials to your home directory		   :mitsetup:
- *Log in to an Athena workstation* using your Athena user name and password
- *Click on the "Ubuntu" button* on the upper-left and type "term" as shown below
#+attr_latex: :width .8\textwidth
 [[./images/OpenTerminal.png]]
- *Click on the "Terminal" icon* as shown above
- In the terminal, *type this line exactly as shown*:
: wget r-stats; unzip r-stats
- If you see "ERROR 404: Not Found", then you mistyped the command--try again, making sure to type the command exactly as shown

** Launch RStudio on Athena					   :mitsetup:
- To start R *type these commands in the terminal*:
:     add r
:     rstudio
- Open up today's R script
  - In RStudio, Go to *File => Open Script*
  - Locate and open the =Rstatistics.R= script in the Rgraphics folder in your home directory
- Go to *Tools => Set working directory => To source file location* (more on the working directory later)
- I encourage you to add your own notes to this file!
 

** Set working directory

It is often helpful to start your R session by setting your working directory so you don't have to type the full path names to your data and other files

#+name: setwed
#+begin_src R :results output
  # set the working directory
  # setwd("~/Desktop/Rstatistics")
  # setwd("C:/Users/dataclass/Desktop/Rstatistics")
#+end_src

#+RESULTS: setwed

You might also start by listing the files in your working directory
#+name: listFiles
#+begin_src R
  getwd() # where am I?
  list.files("dataSets") # files in the dataSets folder
#+end_src

#+RESULTS: listFiles
#+begin_example
[1] "/home/izahn/Documents/Work/Classes/IQSS_Stats_Workshops/R/Rstatistics"
[1] "Exam.rds"          "NatHealth2008MI"   "NatHealth2011.rds"
[4] "states.dta"        "states.rds"
#+end_example

** Load the states data

The /states.dta/ data comes from [[http://anawida.de/teach/SS14/anawida/4.linReg/data/states.dta.txt]] and appears to have originally appeared in /Statistics with Stata/ by Lawrence C. Hamilton.
#+name: loadStates
#+begin_src R
  # read the states data
  states.data <- readRDS("dataSets/states.rds") 
  #get labels
  states.info <- data.frame(attributes(states.data)[c("names", "var.labels")])
  #look at last few labels
  tail(states.info, 8)
#+end_src

#+RESULTS: loadStates
#+begin_example
     names                      var.labels
14    csat        Mean composite SAT score
15    vsat           Mean verbal SAT score
16    msat             Mean math SAT score
17 percent       % HS graduates taking SAT
18 expense Per pupil expenditures prim&sec
19  income Median household income, $1,000
20    high             % adults HS diploma
21 college         % adults college degree
#+end_example


* Linear regression

** Examine the data before fitting models
Start by examining the data to check for problems.

#+BEGIN_SRC R 
  # summary of expense and csat columns, all rows
  sts.ex.sat <- subset(states.data, select = c("expense", "csat"))
  summary(sts.ex.sat)
  # correlation between expense and csat
  cor(sts.ex.sat) 
#+END_SRC

#+RESULTS:
#+begin_example
    expense          csat       
 Min.   :2960   Min.   : 832.0  
 1st Qu.:4352   1st Qu.: 888.0  
 Median :5000   Median : 926.0  
 Mean   :5236   Mean   : 944.1  
 3rd Qu.:5794   3rd Qu.: 997.0  
 Max.   :9259   Max.   :1093.0
           expense       csat
expense  1.0000000 -0.4662978
csat    -0.4662978  1.0000000
#+end_example

** Plot the data before fitting models
Plot the data to look for multivariate outliers, non-linear relationships etc.

#+LATEX: \begin{columns} \column{.9\textwidth} \begin{block}{}
#+name: statsScatter1
#+BEGIN_SRC R :results output graphics :exports both :file images/statesCorr1.png :width 500 :height 400 :R-dev-args res=80
  # scatter plot of expense vs csat
  plot(sts.ex.sat)
#+END_SRC

#+ATTR_LATEX: :width 2.5in  
#+RESULTS: statsScatter1
[[file:images/statesCorr1.png]]


#+LATEX: \end{block} \end{columns}

** Linear regression example
- Linear regression models can be fit with the =lm()= function
- For example, we can use =lm= to predict SAT scores based on per-pupal expenditures:

#+begin_src R
  # Fit our regression model
  sat.mod <- lm(csat ~ expense, # regression formula
                data=states.data) # data set
  # Summarize and print the results
  summary(sat.mod) # show regression coefficients table
#+end_src

#+RESULTS:
#+begin_example

Call:
lm(formula = csat ~ expense, data = states.data)

Residuals:
     Min       1Q   Median       3Q      Max 
-131.811  -38.085    5.607   37.852  136.495 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)  1.061e+03  3.270e+01   32.44  < 2e-16 ***
expense     -2.228e-02  6.037e-03   -3.69 0.000563 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 59.81 on 49 degrees of freedom
Multiple R-squared:  0.2174,	Adjusted R-squared:  0.2015 
F-statistic: 13.61 on 1 and 49 DF,  p-value: 0.0005631
#+end_example

** Why is the association between expense and SAT scores /negative/?

Many people find it surprising that the per-capita expenditure on students is negatively related to SAT scores. The beauty of multiple regression is that we can try to pull these apart. What would the association between expense and SAT scores be if there were no difference among the states in the percentage of students taking the SAT?

#+BEGIN_SRC R
  summary(lm(csat ~ expense + percent, data = states.data))
#+END_SRC

#+RESULTS:
#+begin_example

Call:
lm(formula = csat ~ expense + percent, data = states.data)

Residuals:
    Min      1Q  Median      3Q     Max 
-62.921 -24.318   1.741  15.502  75.623 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) 989.807403  18.395770  53.806  < 2e-16 ***
expense       0.008604   0.004204   2.046   0.0462 *  
percent      -2.537700   0.224912 -11.283 4.21e-15 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 31.62 on 48 degrees of freedom
Multiple R-squared:  0.7857,	Adjusted R-squared:  0.7768 
F-statistic: 88.01 on 2 and 48 DF,  p-value: < 2.2e-16
#+end_example

** The lm class and methods

OK, we fit our model. Now what?
- Examine the model object:

#+name: checkModelObject
#+begin_src R
  class(sat.mod)
  names(sat.mod)
  methods(class = class(sat.mod))[1:9]
#+end_src

#+RESULTS: checkModelObject
#+begin_example
[1] "lm"
 [1] "coefficients"  "residuals"     "effects"       "rank"         
 [5] "fitted.values" "assign"        "qr"            "df.residual"  
 [9] "xlevels"       "call"          "terms"         "model"
[1] "add1.lm"                   "alias.lm"                 
[3] "anova.lm"                  "case.names.lm"            
[5] "coerce,oldClass,S3-method" "confint.lm"               
[7] "cooks.distance.lm"         "deviance.lm"              
[9] "dfbeta.lm"
#+end_example

- Use function methods to get more information about the fit

#+name: confInt
#+begin_src R 
  confint(sat.mod)
  # hist(residuals(sat.mod))
#+end_src

#+RESULTS: confInt
#+begin_example
                   2.5 %        97.5 %
(Intercept) 995.01753164 1126.44735626
expense      -0.03440768   -0.01014361
#+end_example


** Linear Regression Assumptions
- Ordinary least squares regression relies on several assumptions, including that the residuals are normally distributed and homoscedastic, the errors are independent and the relationships are linear.
- Investigate these assumptions visually by plotting your model:
#+LATEX: \begin{columns} \column{.9\textwidth} \begin{block}{}
#+BEGIN_SRC R :results output graphics :exports both :file images/regressionsAssumptions1.png :width 500 :height 200
  par(mar = c(4, 4, 2, 2), mfrow = c(1, 2)) #optional
  plot(sat.mod, which = c(1, 2)) # "which" argument optional
#+END_SRC

#+RESULTS:
[[file:images/regressionsAssumptions1.png]]

#+LATEX: \end{block} \end{columns}

** Comparing models
Do congressional voting patterns predict SAT scores over and above expense? Fit two models and compare them:
#+name: m1demogOnly
#+begin_src R 
  # fit another model, adding house and senate as predictors
  sat.voting.mod <-  lm(csat ~ expense + house + senate,
                        data = na.omit(states.data))
  sat.mod <- update(sat.mod, data=na.omit(states.data))
  # compare using the anova() function
  anova(sat.mod, sat.voting.mod)
  coef(summary(sat.voting.mod))
#+end_src

#+RESULTS: m1demogOnly
#+begin_example
Analysis of Variance Table

Model 1: csat ~ expense
Model 2: csat ~ expense + house + senate
  Res.Df    RSS Df Sum of Sq      F  Pr(>F)  
1     46 169050                              
2     44 149284  2     19766 2.9128 0.06486 .
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
                 Estimate   Std. Error    t value     Pr(>|t|)
(Intercept) 1082.93438041 38.633812740 28.0307405 1.067795e-29
expense       -0.01870832  0.009691494 -1.9303852 6.001998e-02
house         -1.44243754  0.600478382 -2.4021473 2.058666e-02
senate         0.49817861  0.513561356  0.9700469 3.373256e-01
#+end_example


** Exercise 0: least squares regression

Use the /states.rds/ data set. Fit a model predicting  energy consumed per capita (energy) from the percentage of residents living in metropolitan areas (metro). Be sure to 
    1. Examine/plot the data before fitting the model
    2. Print and interpret the model =summary=
    3. =plot= the model to look for deviations from modeling assumptions

Select one or more additional predictors to add to your model and repeat steps 1-3. Is this model significantly better than the model with /metro/ as the only predictor?
       
* Interactions and factors

** Modeling interactions
Interactions allow us assess the extent to which the association between one predictor and the outcome depends on a second predictor. For example: Does the association between expense and SAT scores depend on the median income in the state?
#+name: fitModel2
#+begin_src R  
    #Add the interaction to the model
  sat.expense.by.percent <- lm(csat ~ expense*income,
                               data=states.data) 
  #Show the results
    coef(summary(sat.expense.by.percent)) # show regression coefficients table
#+end_src

#+RESULTS: fitModel2
#+begin_example
                    Estimate   Std. Error   t value     Pr(>|t|)
(Intercept)     1.380364e+03 1.720863e+02  8.021351 2.367069e-10
expense        -6.384067e-02 3.270087e-02 -1.952262 5.687837e-02
income         -1.049785e+01 4.991463e+00 -2.103161 4.083253e-02
expense:income  1.384647e-03 8.635529e-04  1.603431 1.155395e-01
#+end_example

** Regression with categorical predictors
Let's try to predict SAT scores from region, a categorical variable. Note that you must make sure R does not think your categorical variable is numeric. 
#+begin_src R 
  # make sure R knows region is categorical
  str(states.data$region)
  states.data$region <- factor(states.data$region)
  #Add region to the model
  sat.region <- lm(csat ~ region,
                   data=states.data) 
  #Show the results
  coef(summary(sat.region)) # show regression coefficients table
  anova(sat.region) # show ANOVA table
#+end_src

#+RESULTS:
#+begin_example
 Factor w/ 4 levels "West","N. East",..: 3 1 1 3 1 1 2 3 NA 3 ...
               Estimate Std. Error    t value     Pr(>|t|)
(Intercept)   946.30769   14.79582 63.9577807 1.352577e-46
regionN. East -56.75214   23.13285 -2.4533141 1.800383e-02
regionSouth   -16.30769   19.91948 -0.8186806 4.171898e-01
regionMidwest  63.77564   21.35592  2.9863209 4.514152e-03
Analysis of Variance Table

Response: csat
          Df Sum Sq Mean Sq F value    Pr(>F)    
region     3  82049 27349.8  9.6102 4.859e-05 ***
Residuals 46 130912  2845.9                      
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
#+end_example

Again, *make sure to tell R which variables are categorical by converting them to factors!*

** Setting factor reference groups and contrasts
In the previous example we use the default contrasts for region. The default in R is treatment contrasts, with the first level as the reference. We can change the reference group or use another coding scheme using the =C= function.

#+name: getContrasts
#+begin_src R
  # print default contrasts
  contrasts(states.data$region)
  # change the reference group
  coef(summary(lm(csat ~ C(region, base=4),
                  data=states.data)))
  # change the coding scheme
  coef(summary(lm(csat ~ C(region, contr.helmert),
                  data=states.data)))
#+end_src

#+RESULTS: getContrasts
#+begin_example
        N. East South Midwest
West          0     0       0
N. East       1     0       0
South         0     1       0
Midwest       0     0       1
                       Estimate Std. Error   t value     Pr(>|t|)
(Intercept)          1010.08333   15.39998 65.589930 4.296307e-47
C(region, base = 4)1  -63.77564   21.35592 -2.986321 4.514152e-03
C(region, base = 4)2 -120.52778   23.52385 -5.123641 5.798399e-06
C(region, base = 4)3  -80.08333   20.37225 -3.931000 2.826007e-04
                            Estimate Std. Error     t value     Pr(>|t|)
(Intercept)               943.986645   7.706155 122.4977451 1.689670e-59
C(region, contr.helmert)1 -28.376068  11.566423  -2.4533141 1.800383e-02
C(region, contr.helmert)2   4.022792   5.884552   0.6836191 4.976450e-01
C(region, contr.helmert)3  22.032229   4.446777   4.9546509 1.023364e-05
#+end_example

See also =?contrasts=, =?contr.treatment=, and =?relevel=.

** Exercise 1: interactions and factors

Use the states data set.

1. Add on to the regression equation that you created in exercise 1 by generating an interaction term and testing the interaction.

2. Try adding region to the model. Are there significant differences across the four regions?

* Regression with binary outcomes

** Logistic regression
This far we have used the =lm= function to fit our regression models. =lm= is great, but limited--in particular it only fits models for continuous dependent variables. For categorical dependent variables we can use the =glm()= function.

For these models we will use a different dataset, drawn from the National Health Interview Survey. From the [[http://www.cdc.gov/nchs/nhis.htm][CDC website]]:

#+begin_quote
The National Health Interview Survey (NHIS) has monitored the health of the nation since 1957. NHIS data on a broad range of health topics are collected through personal household interviews. For over 50 years, the U.S. Census Bureau has been the data collection agent for the National Health Interview Survey. Survey results have been instrumental in providing data to track health status, health care access, and progress toward achieving national health objectives.
#+end_quote

Load the National Health Interview Survey data:

#+name: NHSdescription
#+begin_src R
  NH11 <- readRDS("dataSets/NatHealth2011.rds")
  labs <- attributes(NH11)$labels
#+end_src

#+RESULTS: NHSdescription

** Logistic regression example

Let's predict the probability of being diagnosed with hypertension based on age, sex, sleep, and bmi

#+name: logit1
#+begin_src R 
  str(NH11$hypev) # check stucture of hypev
  levels(NH11$hypev) # check levels of hypev
  # collapse all missing values to NA
  NH11$hypev <- factor(NH11$hypev, levels=c("2 No", "1 Yes"))
  # run our regression model
  hyp.out <- glm(hypev~age_p+sex+sleep+bmi,
                data=NH11, family="binomial")
  coef(summary(hyp.out))
#+end_src

#+RESULTS: logit1
#+begin_example
 Factor w/ 5 levels "1 Yes","2 No",..: 2 2 1 2 2 1 2 2 1 2 ...
[1] "1 Yes"             "2 No"              "7 Refused"        
[4] "8 Not ascertained" "9 Don't know"
                Estimate   Std. Error    z value     Pr(>|z|)
(Intercept) -4.269466028 0.0564947294 -75.572820 0.000000e+00
age_p        0.060699303 0.0008227207  73.778743 0.000000e+00
sex2 Female -0.144025092 0.0267976605  -5.374540 7.677854e-08
sleep       -0.007035776 0.0016397197  -4.290841 1.779981e-05
bmi          0.018571704 0.0009510828  19.526906 6.485172e-85
#+end_example

** Logistic regression coefficients
Generalized linear models use link functions, so raw coefficients are difficult to interpret. For example, the age coefficient of .06 in the previous model tells us that for every one unit increase in age, the log odds of hypertension diagnosis increases by 0.06. Since most of us are not used to thinking in log odds this is not too helpful!

One solution is to transform the coefficients to make them easier to interpret

#+name: logitcoef2
#+begin_src R
  hyp.out.tab <- coef(summary(hyp.out))
  hyp.out.tab[, "Estimate"] <- exp(coef(hyp.out))
  hyp.out.tab
#+end_src

#+RESULTS: logitcoef2
#+begin_example
 
             Estimate   Std. Error    z value     Pr(>|z|)
(Intercept) 0.01398925 0.0564947294 -75.572820 0.000000e+00
age_p       1.06257935 0.0008227207  73.778743 0.000000e+00
sex2 Female 0.86586602 0.0267976605  -5.374540 7.677854e-08
sleep       0.99298892 0.0016397197  -4.290841 1.779981e-05
bmi         1.01874523 0.0009510828  19.526906 6.485172e-85
#+end_example

** Generating predicted values

In addition to transforming the log-odds produced by =glm= to odds, we can use the =predict()= function to make direct statements about the predictors in our model. For example, we can ask "How much more likely is a 63 year old female to have hypertension compared to a 33 year old female?".

#+name: predDat1
#+begin_src R 
  # Create a dataset with predictors set at desired levels
  predDat <- with(NH11,
                  expand.grid(age_p = c(33, 63),
                              sex = "2 Female",
                              bmi = mean(bmi, na.rm = TRUE),
                              sleep = mean(sleep, na.rm = TRUE)))
  # predict hypertension at those levels
  cbind(predDat, predict(hyp.out, type = "response",
                         se.fit = TRUE, interval="confidence",
                         newdata = predDat))
#+end_src

#+RESULTS: predDat1
#+begin_example
  age_p      sex      bmi   sleep       fit      se.fit residual.scale
1    33 2 Female 29.89565 7.86221 0.1289227 0.002849622              1
2    63 2 Female 29.89565 7.86221 0.4776303 0.004816059              1
#+end_example

This tells us that a 33 year old female has a 13% probability of having been diagnosed with hypertension, while and 63 year old female has a 48% probability of having been diagnosed.

** Packages for  computing and graphing predicted values
Instead of doing all this ourselves, we can use the effects package to compute quantities of interest for us (cf. the Zelig package).

#+LATEX: \begin{columns} \column{.9\textwidth} \begin{block}{}
#+name: predWithEffects
#+begin_src R :results output graphics :file images/effects1.png :exports both :width 500 :height 400 :R-dev-args res=80
  library(effects)
  plot(allEffects(hyp.out))
#+end_src

#+RESULTS: predWithEffects
[[file:images/effects1.png]]
#+LATEX: \end{block} \end{columns}



** Exercise 2: logistic regression
Use the NH11 data set that we loaded earlier.

    1. Use glm  to conduct a logistic regression to predict ever worked (everwrk) using age (age_p) and marital status (r_maritl). 
    2. Predict the probability of working for each level of marital status.

Note that the data is not perfectly clean and ready to be modeled. You will need to clean up at least some of the variables before fitting the model.


* Multilevel Modeling


** Multilevel modeling overview

- Multi-level (AKA hierarchical) models are a type of mixed-effects models 
- Used to model variation due to group membership where the goal is to generalize to a population of groups
- Can model different intercepts and/or slopes for each group
- Mixed-effecs models include two types of predictors: fixed-effects and random effects
  - Fixed-effects -- observed levels are of direct interest (.e.g, sex, political party...)
  - Random-effects -- observed levels not of direct interest: goal is to make inferences to a population represented by observed levels
- In R the lme4 package is the most popular for mixed effects models
  - Use the =lmer= function for liner mixed models, =glmer= for generalized mixed models 

#+name: loadlme4Package
#+begin_src R
  library(lme4)
#+end_src

#+RESULTS: loadlme4Package
#+begin_example
Loading required package: Matrix
#+end_example


#+name: setupR3
#+begin_src R :exports none
  .First <- function() {
    library(Amelia, quietly=TRUE)
    library(lme4, quietly=TRUE)
    options(width=70)
    options(useFancyQuotes=FALSE)
    options(show.signif.stars=FALSE)
    options(scipen = 10)
    options(digits = 3)
  }
#+end_src

#+RESULTS: setupR3


** The Exam data
The Exam data set contans exam scores of 4,059 students from 65 schools in Inner London. The variable names are as follows:

| variable | Description                                                                                        |
|----------+----------------------------------------------------------------------------------------------------|
| school   | School ID - a factor.                                                                              |
| normexam | Normalized exam score.                                                                             |
| schgend  | School gender - a factor.  Levels are 'mixed', 'boys', and 'girls'.                                |
| schavg   | School average of intake score.                                                                    |
| vr       | Student level Verbal Reasoning (VR) score band at intake - 'bottom 25%', 'mid 50%', and 'top 25%'. |
| intake   | Band of student's intake score - a factor.  Levels are 'bottom 25%', 'mid 50%' and 'top 25%'./     |
| standLRT | Standardised LR test score.                                                                        |
| sex      | Sex of the student - levels are 'F' and 'M'.                                                       |
| type     | School type - levels are 'Mxd' and 'Sngl'.                                                         |
| student  | Student id (within school) - a factor                                                              |

#+name: tasdf
#+begin_src R
    Exam <- readRDS("dataSets/Exam.rds")
#+end_src

#+RESULTS: tasdf


** The null model and ICC
 
As a preliminary step it is often useful to partition the variance in the dependent variable into the various levels. This can be accomplished by running a null model (i.e., a model with a random effects grouping structure, but no fixed-effects predictors).

#+name: mixedModel1
#+begin_src R 
  # null model, grouping by school but not fixed effects.
  Norm1 <-lmer(normexam ~ 1 + (1|school),
                data=Exam, REML = FALSE)
  summary(Norm1)
#+end_src

#+RESULTS: mixedModel1
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: normexam ~ 1 + (1 | school)
   Data: Exam

     AIC      BIC   logLik deviance df.resid 
 10825.5  10844.4  -5409.8  10819.5     3984 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.9022 -0.6463  0.0028  0.6981  3.6364 

Random effects:
 Groups   Name        Variance Std.Dev.
 school   (Intercept) 0.1695   0.4117  
 Residual             0.8482   0.9210  
Number of obs: 3987, groups:  school, 65

Fixed effects:
            Estimate Std. Error t value
(Intercept) -0.01415    0.05378  -0.263
#+end_example

The is .169/(.169 + .848) = .17: 17% of the variance is at the school level.
** Adding fixed-effects predictors
Predict exam scores from student's standardized tests scores

#+name: mixedModel2
#+begin_src R 
  Norm2 <-lmer(normexam~standLRT + (1|school),
               data=Exam,
               REML = FALSE) 
  summary(Norm2) 
#+end_src

#+RESULTS: mixedModel2
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: normexam ~ standLRT + (1 | school)
   Data: Exam

     AIC      BIC   logLik deviance df.resid 
  9143.4   9168.5  -4567.7   9135.4     3954 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.7002 -0.6252  0.0238  0.6776  3.2617 

Random effects:
 Groups   Name        Variance Std.Dev.
 school   (Intercept) 0.09193  0.3032  
 Residual             0.56701  0.7530  
Number of obs: 3958, groups:  school, 65

Fixed effects:
            Estimate Std. Error t value
(Intercept) 0.001211   0.040038    0.03
standLRT    0.565588   0.012647   44.72

Correlation of Fixed Effects:
         (Intr)
standLRT 0.007
#+end_example


** Multiple degree of freedom comparisons
As with =lm= and =glm= models, you can compare the two =lmer= models using the =anova= function.

#+name: mixedModelAnova
#+begin_src R 
  anova(Norm1, Norm2)
#+end_src

#+RESULTS: mixedModelAnova
#+begin_example
Error in anova.merMod(Norm1, Norm2) : 
  models were not all fitted to the same size of dataset
#+end_example


** Random slopes 
Add a random effect of students' standardized test scores as well. Now in addition to estimating the distribution of intercepts across schools, we also estimate the distribution of the slope of exam on standardized test.

#+name: mixedModelRandSlope
#+begin_src R 
  Norm3 <- lmer(normexam~standLRT + (standLRT|school), data=Exam,
                 REML = FALSE) 
  summary(Norm3) 
#+end_src

#+RESULTS: mixedModelRandSlope
#+begin_example
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: normexam ~ standLRT + (standLRT | school)
   Data: Exam

     AIC      BIC   logLik deviance df.resid 
  9108.4   9146.1  -4548.2   9096.4     3952 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.8129 -0.6336  0.0331  0.6734  3.4521 

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 school   (Intercept) 0.08985  0.2998       
          standLRT    0.01415  0.1189   0.51
 Residual             0.55516  0.7451       
Number of obs: 3958, groups:  school, 65

Fixed effects:
            Estimate Std. Error t value
(Intercept) -0.01224    0.03972  -0.308
standLRT     0.55863    0.01989  28.080

Correlation of Fixed Effects:
         (Intr)
standLRT 0.371
#+end_example

** Test the significance of the random slope
To test the significance of a random slope just compare models with and without the random slope term 

#+name: mixedModelAnova2
#+begin_src R
  anova(Norm2, Norm3) 
#+end_src

#+RESULTS: mixedModelAnova2
#+begin_example
Data: Exam
Models:
Norm2: normexam ~ standLRT + (1 | school)
Norm3: normexam ~ standLRT + (standLRT | school)
      Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)    
Norm2  4 9143.4 9168.5 -4567.7   9135.4                             
Norm3  6 9108.4 9146.1 -4548.2   9096.4 38.954      2  3.477e-09 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
#+end_example


** Exercise 3: multilevel modeling
Use the dataset, bh1996:
src_R[:exports code :eval no]{data(bh1996, package="multilevel")}

From the data documentation:
#+begin_quote
     Variables are Cohesion (COHES), Leadership Climate (LEAD),
     Well-Being (WBEING) and Work Hours (HRS).  Each of these variables
     has two variants - a group mean version that replicates each group
     mean for every individual, and a within-group version where the
     group mean is subtracted from each individual response.  The group
     mean version is designated with a G. (e.g., G.HRS), and the
     within-group version is designated with a W. (e.g., W.HRS).
#+end_quote

1. Create a null model predicting wellbeing ("WBEING")
2. Calculate the ICC for your null model
3. Run a second multi-level model that adds two individual-level predictors, average number of hours worked ("HRS") and leadership skills ("LEAD") to the model and interpret your output.
4. Now, add a random effect of average number of hours worked ("HRS") to the model and interpret your output.  Test the significance of this random term.


* BONUS ROUND: Multiple imputation                                 :noexport:
  :PROPERTIES:
  :header-args: :eval no
  :END: 

** Multiple imputation
- Majority of datasets contain missing data
- Produces a variety of problems and limitations to data analysis
- Multiple imputation (MI) generates multiple, complete datasets that contain estimations of missing data points

** Multiple imputation
Earlier we wanted to compare a model predicting bmi from demographic variables to a model including demographics and substantive predictors. We omitted missing data so that we could fit both models to the same data. That is a common practice, but it has many problems (which we unfortunately don't have time to discuss in detail). A popular solution is to use multiple imputation to fill in the missing values with reasonable placeholders. 

MI is typically thought of as involving three steps:
  - Selection of imputation model
  - Generation of imputed datasets
  - Combining results across imputed datasets

There are a number of packages for doing this in R: we will use the Amelia package because it is powerful, fast, and easy to use. You can refer to the Amelia documentation for more information about its imputation procedures:
http://r.iq.harvard.edu/docs/amelia/amelia.pdf


** Creating imputed data sets
We're going to create several datasets to look at a model predicting the number of days of work missed/year (wkdayr)

#+name: loadNHsubset
#+begin_src R
  # load the Amelia package
  library(Amelia)
  # help(package="Amelia")
  # load a smaller version of NH
  NH08.mi <- readRDS("dataSets/NatHealth2008MI")
  # generate five imputed data sets
  amelia.log <- capture.output( # suppress amelia's chattiness
    NatHealth.MI <- amelia(NH08.mi,
                           m=5,
                           idvars=c("id")))
#+end_src

#+RESULTS: loadNHsubset
#+begin_example
> # load the Amelia package
> library(Amelia)
> # help(package="Amelia")
> # load a smaller version of NH
> NH08.mi <- readRDS("dataSets/NatHealth2008MI")
> # generate five imputed data sets
> amelia.log <- capture.output( # suppress amelia's chattiness
+   NatHealth.MI <- amelia(NH08.mi,
+                          m=5,
+                          idvars=c("id")))
> 
#+end_example

** Checking imputed values
Compare imputed values to observed values

#+name: setupR2
#+begin_src R :exports none
  .First <- function() {
    library(Amelia, quietly=TRUE)
    options(width=70)
    options(useFancyQuotes=FALSE)
    options(show.signif.stars=FALSE)
    options(scipen = 10)
    options(digits = 3)
  }
#+end_src

#+RESULTS: setupR2
#+begin_example
> .First <- function() {
+   library(Amelia, quietly=TRUE)
+   options(width=70)
+   options(useFancyQuotes=FALSE)
+   options(show.signif.stars=FALSE)
+   options(scipen = 10)
+   options(digits = 3)
+ }
> 
#+end_example


#+LATEX: \begin{columns} \column{.85\textwidth} \begin{block}{}
#+name: compImputed
#+begin_src R :results output graphics :exports both :file images/imputed1.png :width 900 :height 600 :R-dev-args res=120 
  plot(NatHealth.MI, which.vars=9:12)
#+end_src

#+RESULTS: compImputed
[[file:images/imputed1.png]]

#+ATTR_LATEX: :width=4in
#+RESULTS:
[[file:images/imputed1.png]]

#+LATEX: \end{block} \end{columns}


** Checking imputed values: overimputation
Overimputation strategy:
- Treat every observed value as if it was missing
- Impute many values for that observed value
- Examine the correspondence between imputed and observed values

#+LATEX: \begin{columns} \column{.85\textwidth} \begin{block}{}
#+name: overimpute
#+begin_src R :results output graphics :exports both :file images/overImputed.png :width 700 :height 400 :R-dev-args res=120
  overimpute(NatHealth.MI, var="sleep")
#+end_src

#+RESULTS: overimpute
[[file:images/overImputed.png]]

#+ATTR_LATEX: :width=3in
#+RESULTS:
[[file:images/overImputed.png]]


#+LATEX: \end{block} \end{columns}

** Using imputed data sets in regression models

Zelig makes it very easy to use imputed data sets -- just point to the list of imputed data sets in the ~data~ argument

#+name: zeligImputed
#+begin_src R 
  library(Zelig)
  nhImp.out <- zelig(wkdayr ~ cigsday + modmin + sleep, model = "ls",
                     data = NatHealth.MI$imputations, cite = FALSE)
  
  coef(summary(nhImp.out))
#+end_src

#+RESULTS: zeligImputed
#+begin_example
> library(Zelig)
> nhImp.out <- zelig(wkdayr ~ cigsday + modmin + sleep, model = "ls",
+                    data = NatHealth.MI$imputations, cite = FALSE)
> 
> coef(summary(nhImp.out))
              Value Std. Error t-stat p-value
(Intercept) -6.0745     5.6803  -1.07  0.2963
cigsday      0.0252     0.1326   0.19  0.8496
modmin      -0.0318     0.0227  -1.40  0.1610
sleep        1.7233     0.8624   2.00  0.0669
> 
#+end_example


For separate results, use print(summary(x), subset = i:j).

** Exercise 4: multiple imputation
    1. Using Amelia, generate 5 imputed versions of the Exam dataset. Make sure you tell Amelia which variables are nominal, and that school is the id variable.  
    2. Create plots that compare imputed values to observed values
    3. Overimpute the variable "schavg"


* Exercise solutions                                              :prototype:
  :PROPERTIES:
  :header-args: :exports code
  :END:

** Exercise 0 prototype
Use the /states.rds/ data set. 
#+BEGIN_SRC R
  states <- readRDS("dataSets/states.rds")
#+END_SRC

#+RESULTS:

Fit a model predicting  energy consumed per capita (energy) from the percentage of residents living in metropolitan areas (metro). Be sure to 
1. [@1] Examine/plot the data before fitting the model
#+BEGIN_SRC R
  states.en.met <- subset(states, select = c("metro", "energy"))
  summary(states.en.met)
  plot(states.en.met)
  cor(states.en.met, use="pairwise")
#+END_SRC

#+RESULTS:
#+begin_example
     metro            energy     
 Min.   : 20.40   Min.   :200.0  
 1st Qu.: 46.98   1st Qu.:285.0  
 Median : 67.55   Median :320.0  
 Mean   : 64.07   Mean   :354.5  
 3rd Qu.: 81.58   3rd Qu.:371.5  
 Max.   :100.00   Max.   :991.0  
 NA's   :1        NA's   :1
 
           metro     energy
metro   1.0000000 -0.3397445
energy -0.3397445  1.0000000
#+end_example

2. [@2] Print and interpret the model =summary=
#+BEGIN_SRC R
  mod.en.met <- lm(energy ~ metro, data = states)
  summary(mod.en.met)
#+END_SRC

#+RESULTS:
#+begin_example

Call:
lm(formula = energy ~ metro, data = states)

Residuals:
    Min      1Q  Median      3Q     Max 
-215.51  -64.54  -30.87   18.71  583.97 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) 501.0292    61.8136   8.105 1.53e-10 ***
metro        -2.2871     0.9139  -2.503   0.0158 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 140.2 on 48 degrees of freedom
  (1 observation deleted due to missingness)
Multiple R-squared:  0.1154,	Adjusted R-squared:  0.097 
F-statistic: 6.263 on 1 and 48 DF,  p-value: 0.01578
#+end_example

3. [@3] =plot= the model to look for deviations from modeling assumptions
#+BEGIN_SRC R :results output graphics :file images/ex1.png
  plot(mod.en.met)
#+END_SRC

#+RESULTS:
[[file:images/ex1.png]]

Select one or more additional predictors to add to your model and repeat steps 1-3. Is this model significantly better than the model with /metro/ as the only predictor?
#+BEGIN_SRC R
  states.en.met.pop.wst <- subset(states, select = c("energy", "metro", "pop", "waste"))
  summary(states.en.met.pop.wst)
  plot(states.en.met.pop.wst)
  cor(states.en.met.pop.wst, use = "pairwise")
  mod.en.met.pop.waste <- lm(energy ~ metro + pop + waste, data = states)
  summary(mod.en.met.pop.waste)
  anova(mod.en.met, mod.en.met.pop.waste)
#+END_SRC

#+RESULTS:
#+begin_example
     energy          metro             pop               waste       
 Min.   :200.0   Min.   : 20.40   Min.   :  454000   Min.   :0.5400  
 1st Qu.:285.0   1st Qu.: 46.98   1st Qu.: 1299750   1st Qu.:0.8225  
 Median :320.0   Median : 67.55   Median : 3390500   Median :0.9600  
 Mean   :354.5   Mean   : 64.07   Mean   : 4962040   Mean   :0.9888  
 3rd Qu.:371.5   3rd Qu.: 81.58   3rd Qu.: 5898000   3rd Qu.:1.1450  
 Max.   :991.0   Max.   :100.00   Max.   :29760000   Max.   :1.5100  
 NA's   :1       NA's   :1        NA's   :1          NA's   :1
           energy      metro        pop      waste
energy  1.0000000 -0.3397445 -0.1840357 -0.2526499
metro  -0.3397445  1.0000000  0.5653562  0.4877881
pop    -0.1840357  0.5653562  1.0000000  0.5255713
waste  -0.2526499  0.4877881  0.5255713  1.0000000

Call:
lm(formula = energy ~ metro + pop + waste, data = states)

Residuals:
    Min      1Q  Median      3Q     Max 
-224.62  -67.48  -31.76   12.65  589.48 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)  5.617e+02  9.905e+01   5.671    9e-07 ***
metro       -2.079e+00  1.168e+00  -1.780   0.0816 .  
pop          1.649e-06  4.809e-06   0.343   0.7332    
waste       -8.307e+01  1.042e+02  -0.797   0.4295    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 142.2 on 46 degrees of freedom
  (1 observation deleted due to missingness)
Multiple R-squared:  0.1276,	Adjusted R-squared:  0.07067 
F-statistic: 2.242 on 3 and 46 DF,  p-value: 0.09599
Analysis of Variance Table

Model 1: energy ~ metro
Model 2: energy ~ metro + pop + waste
  Res.Df    RSS Df Sum of Sq      F Pr(>F)
1     48 943103                           
2     46 930153  2     12949 0.3202 0.7276
#+end_example

** Exercise 1: prototype

Use the states data set.

1. Add on to the regression equation that you created in exercise 1 by generating an interaction term and testing the interaction.
#+BEGIN_SRC R
  mod.en.metro.by.waste <- lm(energy ~ metro * waste, data = states)
#+END_SRC

#+RESULTS:

2. Try adding a region to the model. Are there significant differences across the four regions?
#+BEGIN_SRC R
  mod.en.region <- lm(energy ~ metro * waste + region, data = states)
  anova(mod.en.region)
#+END_SRC

#+RESULTS:
#+begin_example
Analysis of Variance Table

Response: energy
            Df Sum Sq Mean Sq F value  Pr(>F)  
metro        1 123064  123064  6.4435 0.01484 *
waste        1  10572   10572  0.5535 0.46093  
region       3 111128   37043  1.9395 0.13749  
metro:waste  1    156     156  0.0082 0.92835  
Residuals   43 821247   19099                  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
#+end_example

** Exercise 2 prototype
Use the NH11 data set that we loaded earlier. Note that the data is not perfectly clean and ready to be modeled. You will need to clean up at least some of the variables before fitting the model.

1. [@1] Use glm  to conduct a logistic regression to predict ever worked (everwrk) using age (age_p) and marital status (r_maritl). 
#+BEGIN_SRC R
  nh11.wrk.age.mar <- subset(NH11, select = c("everwrk", "age_p", "r_maritl"))
  summary(nh11.wrk.age.mar)
  NH11 <- transform(NH11,
                    everwrk = factor(everwrk,
                        levels = c("1 Yes", "2 No")),
                    r_maritl = droplevels(r_maritl))

  mod.wk.age.mar <- glm(everwrk ~ age_p + r_maritl, data = NH11,
                        family = "binomial")

  summary(mod.wk.age.mar)
#+END_SRC

#+RESULTS:
#+begin_example
 
             everwrk          age_p      
 1 Yes            :12153   Min.   :18.00  
 2 No             : 1887   1st Qu.:33.00  
 7 Refused        :   17   Median :47.00  
 8 Not ascertained:    0   Mean   :48.11  
 9 Don't know     :    8   3rd Qu.:62.00  
 NA's             :18949   Max.   :85.00  
                                          
                            r_maritl    
 1 Married - spouse in household:13943  
 7 Never married                : 7763  
 5 Divorced                     : 4511  
 4 Widowed                      : 3069  
 8 Living with partner          : 2002  
 6 Separated                    : 1121  
 (Other)                        :  605

Call:
glm(formula = everwrk ~ age_p + r_maritl, family = "binomial", 
    data = NH11)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.0436  -0.5650  -0.4391  -0.3370   2.7308  

Coefficients:
                                             Estimate Std. Error z value
(Intercept)                                 -0.440248   0.093538  -4.707
age_p                                       -0.029812   0.001645 -18.118
r_maritl2 Married - spouse not in household  0.049675   0.217310   0.229
r_maritl4 Widowed                            0.683618   0.084335   8.106
r_maritl5 Divorced                          -0.730115   0.111681  -6.538
r_maritl6 Separated                         -0.128091   0.151366  -0.846
r_maritl7 Never married                      0.343611   0.069222   4.964
r_maritl8 Living with partner               -0.443583   0.137770  -3.220
r_maritl9 Unknown marital status             0.395480   0.492967   0.802
                                            Pr(>|z|)    
(Intercept)                                 2.52e-06 ***
age_p                                        < 2e-16 ***
r_maritl2 Married - spouse not in household  0.81919    
r_maritl4 Widowed                           5.23e-16 ***
r_maritl5 Divorced                          6.25e-11 ***
r_maritl6 Separated                          0.39742    
r_maritl7 Never married                     6.91e-07 ***
r_maritl8 Living with partner                0.00128 ** 
r_maritl9 Unknown marital status             0.42241    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 11082  on 14039  degrees of freedom
Residual deviance: 10309  on 14031  degrees of freedom
  (18974 observations deleted due to missingness)
AIC: 10327

Number of Fisher Scoring iterations: 5
#+end_example

2. [@2] Predict the probability of working for each level of marital status.
#+BEGIN_SRC R
  library(effects)
  data.frame(Effect("r_maritl", mod.wk.age.mar))
#+END_SRC

#+RESULTS:
#+begin_example
                             r_maritl        fit         se      lower
1     1 Married - spouse in household 0.10822000 0.04413754 0.10014980
2 2 Married - spouse not in household 0.11310823 0.21326041 0.07746061
3                           4 Widowed 0.19381087 0.06806325 0.17381358
4                          5 Divorced 0.05524394 0.10272953 0.04562877
5                         6 Separated 0.09646417 0.14579706 0.07426824
6                     7 Never married 0.14611000 0.05978759 0.13208775
7               8 Living with partner 0.07224958 0.13285112 0.05662466
8            9 Unknown marital status 0.15270076 0.49100994 0.06440837
       upper
1 0.11685606
2 0.16227532
3 0.21550873
4 0.06674358
5 0.12440219
6 0.16134411
7 0.09176661
8 0.32055728
#+end_example



** Exercise 3 prototype
Use the dataset, bh1996:
#+BEGIN_SRC R
  data(bh1996, package="multilevel")

#+END_SRC

#+RESULTS:
#+begin_example
Error in find.package(package, lib.loc, verbose = verbose) : 
  there is no package called ‘multilevel’
#+end_example

From the data documentation:
#+begin_quote
     Variables are Cohesion (COHES), Leadership Climate (LEAD),
     Well-Being (WBEING) and Work Hours (HRS).  Each of these variables
     has two variants - a group mean version that replicates each group
     mean for every individual, and a within-group version where the
     group mean is subtracted from each individual response.  The group
     mean version is designated with a G. (e.g., G.HRS), and the
     within-group version is designated with a W. (e.g., W.HRS).
#+end_quote
Note that the group identifier is named "GRP".
1. [@1] Create a null model predicting wellbeing ("WBEING")
#+BEGIN_SRC R
  library(lme4)
  mod.grp0 <- lmer(WBEING ~ 1 + (1 | GRP), data = bh1996)
  summary(mod.grp0)
#+END_SRC

#+RESULTS:
#+begin_example
Error: 'data' not found, and some variables missing from formula environment
Error in summary(mod.grp0) : object 'mod.grp0' not found
#+end_example
=> library(lme4)
> mod.grp0 <- lmer(WBEING ~ 1 + (1 | GRP), data = bh1996)
> summary(mod.grp0)
Linear mixed model fit by REML ['lmerMod']
Formula: WBEING ~ 1 + (1 | GRP)
   Data: bh1996

REML criterion at convergence: 19347

Scaled residuals: 
   Min     1Q Median     3Q    Max 
-3.322 -0.648  0.031  0.718  2.667 

Random effects:
 Groups   Name        Variance Std.Dev.
 GRP      (Intercept) 0.0358   0.189   
 Residual             0.7895   0.889   
Number of obs: 7382, groups:  GRP, 99

Fixed effects:
            Estimate Std. Error t value
(Intercept)   2.7743     0.0222     125
> 
=2. [@2] Calculate the ICC for your null model
 ~ICC = .0358/(.0358 + .7895) = .04~
3. [@3] Run a second multi-level model that adds two individual-level predictors, average number of hours worked ("HRS") and leadership skills ("LEAD") to the model and interpret your output.
#+BEGIN_SRC R
  mod.grp1 <- lmer(WBEING ~ HRS + LEAD + (1 | GRP), data = bh1996)
  summary(mod.grp1)
#+END_SRC

#+RESULTS:
#+begin_example
Error: 'data' not found, and some variables missing from formula environment
Error in summary(mod.grp1) : object 'mod.grp1' not found
#+end_example

4. [@4] Now, add a random effect of average number of hours worked ("HRS") to the model and interpret your output.  Test the significance of this random term.
#+BEGIN_SRC R
  mod.grp2 <- lmer(WBEING ~ HRS + LEAD + (1 + HRS | GRP), data = bh1996)
  anova(mod.grp1, mod.grp2)
#+END_SRC

#+RESULTS:
#+begin_example
Error: 'data' not found, and some variables missing from formula environment
Error in anova(mod.grp1, mod.grp2) : object 'mod.grp1' not found
#+end_example


* Wrap-up

** Help us make this workshop better!
- Please take a moment to fill out a very short 
feedback form 
- These workshops exist for you -- tell us what you need! 
- http://tinyurl.com/RstatisticsFeedback


** Additional resources
- IQSS workshops: http://projects.iq.harvard.edu/rtc/filter_by/workshops
- IQSS statistical consulting: http://dss.iq.harvard.edu
- Zelig
  - Website: http://gking.harvard.edu/zelig
  - Documentation: http://r.iq.harvard.edu/docs/zelig.pdf
- Ameila
  - Website: http://gking.harvard.edu/Amelia/
  - Documetation: http://r.iq.harvard.edu/docs/amelia/amelia.pdf

* Cleanup							   :noexport:
#+name: cleanitallup
#+begin_src R 
  rm(list=ls())
#+end_src

#+RESULTS: cleanitallup

